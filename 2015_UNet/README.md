# U-Net: Convolutional Networks for Biomedical Image Segmentation

U-Net：用于生物医学图像分割的卷积网络

## Abstract

人们普遍认为，成功训练深度网络需要数千个带注释的训练样本。在本文中，我们提出了一种网络和训练策略，该策略依赖于数据增强的强大使用来更有效地使用可用的注释样本。该架构由用于捕获上下文的收缩路径和能够实现精确定位的对称扩展路径组成。我们表明，这样的网络可以从很少的图像进行端到端训练，并且在 ISBI 挑战上优于先前的最佳方法 (滑动窗口卷积网络)，用于在电子显微镜堆栈中分割神经元结构。使用在透射光学显微镜图像 (相位对比度和 DIC) 上训练的相同网络，我们在很大程度上赢得了 2015 年 ISBI 细胞跟踪挑战赛。此外，网络速度很快。在最近的 GPU 上，512x512 图像的分割需要不到一秒钟。完整的实现 (基于 Caffe) 和经过训练的网络可在 http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net 获得。

## Introduction

在过去的几年里，深度卷积网络在许多视觉识别任务中都优于最先进的技术。虽然卷积网络已经存在很长时间，但由于可用训练集的大小和所考虑的网络的大小，它们的成功受到限制。Krizhevsky 等人的突破是由于在具有 100 万个训练图像的 ImageNet 数据集上使用 8 层和数百万个参数的大型网络进行监督训练。从那时起，已经训练了更大更深的网络。

典型的卷积网络的常见应用是在分类任务上，其中图像的输出是一个单一的类别标签。然而，在许多视觉任务中，特别是在生物医学图像处理中，期望的输出应该包括定位，即每个像素都应该被分配一个类别标签。此外，在生物医学任务中通常无法获得成千上万张训练图像。因此，Ciresan 等人在一个滑动窗口设置中训练了一个网络，通过提供围绕该像素的局部区域 (补丁) 作为输入来预测每个像素的类别标签。首先，这个网络可以实现定位。其次，以补丁形式的训练数据远远大于训练图像的数量。由此产生的网络在 ISBI 2012 的 EM 分割挑战中以较大的优势获胜。 

显然，Ciresan 等人的策略有两个缺点。首先，它非常慢，因为网络必须分别针对每个补丁运行，并且由于重叠补丁而存在大量冗余。其次，定位精度与上下文使用之间存在权衡。更大的补丁需要更多的最大池化层，这会降低定位精度，而较小的补丁使网络只能看到很少的上下文。最近的一些方法提出了一个分类器输出，它考虑了来自多个层的特征。良好的定位和上下文的使用可以同时实现。

在本文中，我们基于一种更加优雅的架构，即所谓的“全卷积网络”。我们修改和扩展了这个架构，使其能够使用很少的训练图像并产生更精确的分割结果；请参见图1。全卷积网络中的主要思想是通过连续的层来补充常规的收缩网络，其中池化操作符被上采样操作符替换。因此，这些层增加了输出的分辨率。为了实现定位，从收缩路径中获得的高分辨率特征与上采样输出相结合。然后，连续的卷积层可以根据这些信息学习组合更精确的输出。

![image-20240311161958358](C:/Users/ZL/AppData/Roaming/Typora/typora-user-images/image-20240311161958358.png)

我们架构中的一个重要修改是，在上采样部分，我们还具有大量的特征通道，这使得网络能够将上下文信息传播到更高分辨率的层。因此，扩张路径与收缩路径更或多或少对称，并产生了 U 形架构。网络没有任何全连接层，只使用每个卷积的有效部分，即分割图仅包含对于输入图像中的完整上下文可用的像素。这种策略通过重叠平铺策略实现了任意大小图像的无缝分割 (见图2) 。为了预测图像边界区域中的像素，缺失的上下文通过镜像输入图像来外推。这种平铺策略对于将网络应用于大型图像非常重要，因为否则分辨率将受到 GPU 内存的限制。

![image-20240311162022978](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403111654292.png)

对于我们的任务，由于可用的训练数据非常有限，我们通过对可用的训练图像应用弹性变形来进行大量数据增强。这使得网络能够学习对这些变形的不变性，而无需在标注图像语料库中看到这些变换。这在生物医学分割中尤为重要，因为变形曾经是组织中最常见的变异，而且可以有效地模拟出真实的变形。数据增强对学习不变性的价值已经在 Dosovitskiy 等人的研究中得到了证明，该研究是关于无监督特征学习的。

许多细胞分割任务中的另一个挑战是分离相同类别的接触对象；请参见图 3。为此，我们提出使用加权损失，其中接触细胞之间的分离背景标签在损失函数中获得较大的权重。

![image-20240311162058431](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403111654867.png)

所得到的网络可应用于各种生物医学分割问题。在本文中，我们展示了在 EM 堆栈中神经结构的分割结果 (这是一个从 ISBI 2012 开始的持续竞赛) ，在这里我们的网络胜过了 Ciresan 等人的网络。此外，我们展示了来自 ISBI 细胞跟踪挑战 2015 的透射光显微图像的细胞分割结果。在这里，我们在最具挑战性的两个 2D 透射光数据集上取得了很大的优势。

## Network Architecture

网络架构如图 1 所示。它包括一个收缩路径 (左侧) 和一个扩张路径 (右侧) 。收缩路径遵循典型的卷积网络架构。它由两个 3x3 卷积 (未填充的卷积) 的重复应用组成，每个卷积后跟一个修正线性单元 (ReLU) 和一个步长为 2 的 2x2 最大池化操作进行下采样。在每个下采样步骤中，我们将特征通道的数量加倍。扩张路径中的每个步骤包括对特征图的上采样，然后是一个 2x2 的卷积 (“上卷积”) ，将特征通道数量减半，与收缩路径中相应裁剪的特征图连接，以及两个 3x3 卷积，每个卷积后跟一个 ReLU。裁剪是由于每个卷积中边缘像素的丢失而必要的。在最终层中，使用 1x1 卷积将每个 64 维特征向量映射到所需的类别数。总共，网络有 23 个卷积层。

为了允许对输出分割图进行无缝平铺 (见图 2) ，重要的是选择输入平铺大小，以便所有 2x2 最大池化操作都应用于具有偶数 x 和 y 大小的层。

## Training

输入图像及其对应的分割图用于通过Caffe[6]的随机梯度下降实现来训练网络。由于未填充的卷积，输出图像小于恒定边界宽度的输入。为了最大限度地减少开销并最大限度地利用 GPU 内存，我们在大批量上偏爱大型输入块，从而将批次减少到单个图像。因此，我们使用高动量 (0.99)，使得大量先前看到的训练样本决定了当前优化步骤中的更新。

能量函数由最终特征图上的像素级软最大值与交叉熵损失函数相结合来计算。$softmax$ 定义为$p_k(\mathbf{x})=\exp(a_k(\mathbf{x}))/\left(\sum_{k^{\prime}=1}^K\exp(a_{k^{\prime}}(\mathbf{x}))\right)$，其中表 $a_k(\mathbf{x})$ 示像素位置 $\mathrm{x}\in\mathit{\Omega}$ 处特征通道 $k$ 的激活，$\Omega\subset\mathbb{Z}^2$。 $K$ 是类别的数量，$p_k(\mathbf{x})$ 是近似的最大函数。对于所有其他 $k$ 具有最大激活 $a_k(\mathbf{x})$ 和 $p_k(\mathbf{x})≈0$ 的 $k$，即$p_k(\mathbf{x})≈1$。然后，交叉熵在每个位置惩罚 $p_{\ell(\mathbf{x})}(\mathbf{x})$ 与 1 的偏差，使用

$E=\sum_{\mathbf{x}\in\Omega}w(\mathbf{x})\log(p_{\ell(\mathbf{x})}(\mathbf{x}))$

其中 $\ell:\Omega\to\{1,\ldots,K\}$ 是每个像素的真实标签，$w:\Omega\to\mathbb{R}$ 是我们引入的权重图，以在训练中赋予一些像素更多重要性。

我们预先计算每个真值分割的权重图，以补偿训练数据集中某个类别的像素的不同频率，并迫使网络学习我们在接触单元之间引入的小分离边界（见图 3c 和 d）。

分离边界是使用形态学操作计算的。然后将权重图计算为

$w(\mathbf{x})=w_c(\mathbf{x})+w_0\cdot\exp\left(-\frac{(d_1(\mathbf{x})+d_2(\mathbf{x}))^2}{2\sigma^2}\right)$

其中 $w_c:\Omega\to\mathbb{R}$ 是平衡类别频率的权重图，$d_1:\Omega\to\mathbb{R}$ 表示到最细胞边界的距离，$d_2:\Omega\to\mathbb{R}$ 表示到第二最近细胞边界的距离。在我们的实验中，我们设置 $w_0=10$ 和 $σ ≈ 5$ 像素。

在具有许多卷积层和通过网络不同路径的深度网络中，权重的良好初始化非常重要。否则，网络的一部分可能会给出过多的激活，而其他部分永远不会贡献。理想情况下，应该调整初始权重，以便网络中的每个特征图具有近似单位方差。对于具有我们的架构（交替卷积和 ReLU 层）的网络，这可以通过从标准差为 $\sqrt{2/N}$ 的高斯分布中提取初始权重来实现，其中 $N$ 表示单个神经元的传入节点数。例如对于前一层的 3x3 卷积和 64 个特征通道 $N = 9·64=576$。

## Data Augmentation

当只有少量训练样本可用时，数据增强对于教授网络所需的不变性和鲁棒性属性至关重要。在显微镜图像的情况下，我们主要需要位移和旋转不变性以及对变形和灰度值变化的鲁棒性。特别是训练样本的随机弹性变形似乎是训练具有非常少的注释图像的分割网络的关键概念。我们使用粗糙的 3x3 网格上的随机位移向量生成平滑变形。这些位移是从标准差为 10 个像素的高斯分布中采样得到的。然后，使用双三次插值计算每个像素的位移。在收缩路径末端的 dropout 层执行进一步的隐式数据增强。

## Experiments

我们展示了 u-net 在三个不同的分割任务中的应用。第一个任务是在电子显微镜记录中对神经结构进行分割。数据集的示例和我们获得的分割结果如图 2 所示。我们提供完整的结果作为附加材料。该数据集由 EM 分割挑战提供，该挑战始于 ISBI 2012 年，并仍然接受新的贡献。训练数据是来自果蝇第一龄幼虫腹神经索 (VNC) 的连续切片透射电子显微镜的 30 个图像 (512x512像素) 的集合。每个图像都带有相应的完全注释的细胞 (白色) 和膜 (黑色) 的地真值分割图。测试集是公开可用的，但其分割图保持秘密。可以通过将预测的膜概率地图发送给组织者来获得评估。评估是通过在 10 个不同级别上对地图进行阈值处理并计算“扭曲错误”、“Rand错误”和“像素错误”来完成的。

u-net (对输入数据的 7 个旋转版本求平均) 在没有任何进一步的预处理或后处理的情况下获得了 0.0003529 的扭曲错误 (新的最佳得分，见表1) 和 0.0382 的 Rand 错误。

这显然比 Ciresan 等人的滑动窗口卷积网络结果更好。[1]，其最佳提交的扭曲错误为 0.000420，Rand 错误为 0.0504。在 Rand 错误方面，在这个数据集上表现更好的唯一算法使用高度数据集特定的后处理方法应用于 Ciresan 等人的概率图。

我们还将 u-net 应用于光学显微图像中的细胞分割任务。该分割任务是 ISBI 细胞跟踪挑战 2014 和 2015 年的一部分。第一个数据集 “PhC-U373” 包含通过相差显微镜记录的聚丙烯酰胺基底上的胶质母细胞瘤 U373 细胞。它包含 35 个部分注释的训练图像。在这里，我们实现了 92% 的平均 IOU (“交并比”) ，明显优于 83% 的第二好算法。第二个数据集 “DIC-HeLa” 是通过差分干涉对比 (DIC) 显微镜记录的平板玻璃上的 HeLa 细胞。它包含 20 个部分注释的训练图像。在这里，我们实现了 77.5% 的平均 IOU，明显优于 46% 的第二好算法。

![image-20240311162133612](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403111621711.png)

![image-20240311162226755](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403111654784.png)

![image-20240311162248588](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403111654791.png)

## Conclusion

u-net 架构在非常不同的生物医学分割应用中取得了非常好的性能。由于弹性变形的数据增强，它只需要非常少量的注释图像，并且在 NVidia Titan GPU (6 GB) 上只需要很合理的训练时间，仅为10小时。我们提供了基于 Caffe 的完整实现和训练的网络。我们确信 u-net 架构可以轻松应用于更多任务。