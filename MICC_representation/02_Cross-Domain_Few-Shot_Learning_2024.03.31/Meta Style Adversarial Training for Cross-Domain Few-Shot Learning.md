# StyleAdv: Meta Style Adversarial Training for Cross-Domain Few-Shot Learning

StyleAdv：用于跨域小样本学习的原风格对抗训练

## Abstract

跨域小样本学习 (CD-FSL) 是最近一项新兴的任务，它解决了不同领域的小样本学习问题。它旨在将在源数据集中学到的先验知识转移到新的目标数据集。CD-FSL 任务尤其受到不同数据集的巨大领域差距的挑战。至关重要的是，这种领域差距实际上来自于视觉风格的变化，Wave-SAN 经验表明，跨越源数据的风格分布有助于缓解这个问题。然而，Wave-SAN 只是简单地交换两幅图像的风格。这样的普通操作使生成的样式“真实”和“简单”仍然属于源样式的原始集合。因此，受 vanilla 对抗性学习的启发，我们提出了一种用于 CD-FSL 的新型与模型无关的元风格对抗训练 (StyleAdv) 方法以及一种新颖的风格对抗性攻击方法。特别是，我们的风格攻击方法综合了“虚拟”和“硬”对抗性风格进行模型训练。这是通过用有符号的风格梯度扰动原始风格来实现的。通过不断攻击风格并迫使模型识别这些具有挑战性的对抗性风格，我们的模型逐渐对视觉风格具有鲁棒性，从而提高了新目标数据集的泛化能力。除了典型的基于 CNN 的主干之外，我们还在大规模预训练视觉转换器上使用我们的 StyleAdv 方法。在八个不同目标数据集上进行的大量实验证明了我们方法的有效性。无论是建立在 ResNet 还是 ViT 的基础上，我们实现了 CD-FSL 的最新技术。

## Introduction

本文研究了跨域少样本学习 (CD-FSL) 的任务，该任务旨在解决了不同领域的小样本学习 (FSL) 问题。作为 FSL 的一般方法，基于情节的元学习策略也被用于训练 CD-FSL 模型，例如，FWT、LRP、ATA 和 Wave-SAN。一般来说，为了在测试阶段模拟低样本状态，元学习采样情节来训练模型。每一个情节包含一个小的有标记的支持集和一个无标记的查询集。模型通过根据支持集预测查询集中包含的图像类别来学习元知识。学习到的元知识直接将模型泛化到新的目标类。

根据经验，我们发现源数据和目标数据之间视觉外观的变化是导致 CD-FSL 中域差异的关键原因之一。有趣的是，WaveSAN，我们之前的工作表明可以通过增强源图像的视觉风格来缓解域差异问题。特别是，Wave-SAN 建议以自适应实例归一化 (AdaIN) 的形式增加样式，方法是随机采样两个源情节并交换它们的风格。然而，尽管 Wave-SAN 很有效，但这种 näıve 风格的生成方法存在两个局限性：1) 交换操作使样式始终限制在源数据集的“真实”风格集中；2) 有限的真实风格进一步导致生成的风格过于“容易”而无法学习。因此，一个自然的问题是我们是否可以合成“虚拟”和“硬”风格来学习更强大的 CD-FSL 模型？形式上，我们使用“真实/虚拟”来指示风格是否最初出现在源风格集中，并将“简单/困难”定义为新风格是否使元任务更加困难。

为此，我们从对抗训练中汲取灵感，提出了一种新的 CD-FSL 元风格对抗训练方法 (StyleAdv)。StyleAdv 在元训练的两个迭代优化循环中玩极小极大游戏。特别是，内循环通过添加扰动从原始源风格生成对抗性风格。合成的对抗性风格对于当前的模型来说应该更具挑战性，从而增加了损失。虽然外循环通过最小化识别具有原始风格和对抗性风格的图像的损失来优化整个网络。我们的最终目标是使模型能够学习一个除了源数据相对有限和简单的风格之外，对各种风格具有鲁棒性的模型。这可以潜在地提高具有视觉外观变化的新目标域的泛化能力。

形式上，我们引入了一种新的风格对抗性攻击方法来支持 StyleAdv 的内部循环。与之前攻击方法不同，我们的风格攻击方法扰动和合成风格，而不是图像像素或特征。从技术上讲，我们首先从输入特征图中提取风格，并在前向计算链中包含提取的风格，以获得每个训练步骤的梯度。之后，我们通过将一定比例的梯度添加到原始风格来合成新的风格。我们的风格对抗性攻击方法合成的风格具有“硬”和“虚拟”的良好属性。特别是，由于我们以训练梯度的相反方向扰动风格，我们的生成会导致“硬”风格。我们的攻击方法产生了与原始源风格完全不同的完全“虚拟”风格。

关键的是，我们的风格攻击方法使用变化的风格扰动比使得风格合成是渐进式的，这使得它与普通对抗性攻击方法有很大不同。具体来说，我们提出了一种新颖的渐进式风格合成策略。直接插入扰动的 näıve 解决方案是单独攻击特征嵌入模块的每个块，然而，这可能会导致特征与高级块的偏差很大。因此，我们的策略是使当前块的合成信号由先前块的对抗性风格累积。另一方面，我们不是通过固定攻击率来攻击模型，而是通过从候选池中随机采样扰动率来合成新的风格。这有助于合成对抗风格的多样性。实验结果表明了我们方法的有效性：1) 我们的风格对抗性攻击方法确实合成了更具挑战性的风格，从而推动了源视觉分布的限制；2) 我们的 StyleAdv 显着提高了基础模型并优于所有其他 CD-FSL 竞争对手。

我们强调我们的 StyleAdv 与其他现有的 FSL 或 CD-FSL 模型无关和互补，例如 GNN 和 FWT。更重要的是，为了从大规模预训练模型 (例如 DINO)中受益，我们进一步探索了调整我们的 StyleAdv 以非参数方式改进 Vision Transformer (ViT)  主干。在实验中，我们表明 StyleAdv 不仅改进了基于 CNN 的 FSL/CD-FSL 方法，而且改进了大规模预训练的 ViT 模型。

最后，我们总结了我们的贡献。1) 针对 CD-FSL 提出了一种新的元风格对抗训练方法 StyleAdv。StyleAdv 通过先扰动原始风格，然后强制模型学习这种对抗性风格，提高了 CD-FSL 模型的鲁棒性。2) 我们提出了一种新的基于变化的攻击率的渐进合成策略的风格攻击方法，因此生成了不同的“虚拟”和“硬”风格。。3) 我们的方法与现有的 FSL 和 CD-FSL 方法是互补的；我们在基于 CNN 和基于 ViT 的主干上验证了我们的想法。4) 在 8 个未见的目标数据集的广泛结果表明，我们的 StyleAdv 优于以前的 CD-FSL 方法，构建了一个新的 SOTA 结果。

## Related Work

**Cross-Domain Few-Shot Learning：**旨在将模型从对海量标注的数据的依赖中解放出来的小样本学习已经研究了许多年。特别是，最近的一些工作，例如 CLIP、CoOp、CLIP-Adapter、Tip-Adapter 和 PMF 探索了用大规模预训练模型促进 FSL。特别是，PMF 贡献了一个简单的管道，并为 FSL 构建了一个 SOTA。作为FSL的扩展任务，CD-FSL 主要解决跨不同领域的 FSL。典型的基于元学习的 CD-FSL 方法包括 FWT、LRP、ATA、AFA 和 Wave-SAN。具体来说，FWT 和 LRP 通过细化批量归一化层并使用解释模型来指导训练来解决 CD-FSL。ATA、AFA 和 Wave-SAN 分别建议增强图像像素、特征和视觉风格。还探索了几种基于迁移学习的 CD-FSL 方法，例如 BSCD-FSL (也称为微调)、BSR 和 NSAE。这些方法表明微调有助于提高目标数据集的性能。引入额外数据或需要多个域数据集进行训练的其他工作包括 STARTUP、Meta-FDMixup、Me-D2N、TGDM、TriAE 和 DSL。

**Adversarial Attack：**对抗性攻击旨在通过向输入数据添加一些定制的扰动来误导模型。为了有效地产生扰动，人们提出了许多对抗性攻击方法。大多数工作攻击图像像素。具体来说，FGSM 和 PGD 是两个最经典和最著名的攻击算法。一些工作攻击特征空间。关键的是，很少有工作攻击风格。与旨在误导模型的这些工作不同，我们扰动风格来解决 CD-FSL 的视觉偏移问题。

**Adversarial Few-Shot Learning：**已经进行了几次探索 FSL 对抗学习的尝试。其中，MDAT、AQ 和MetaAdv 首先攻击输入图像，然后利用攻击图像训练模型，提高对抗样本的防御能力。Shen等人攻击情节的特征，提高 FSL 模型的泛化能力。请注意，ATA 和 AFA，两种 CD-FSL 方法也采用了对抗性学习。但是，我们与他们有很大的不同。ATA 和 AFA 扰动图像像素或特征，而我们的目标是通过生成不同的硬风格来弥合视觉差距。

**Style Augmentation for Domain Shift Problem：**在域生成、图像分割、人员重识别和 CD-FSL 中探索了增强风格分布以缩小域偏移问题。具体来说，MixStyle、AdvStyle、DSU 和 Wave-SAN 通过混合、攻击、从高斯分布采样和交换来合成没有额外参数的风格。MaxStyle 和L2D 需要额外的网络模块和复杂的辅助任务来帮助生成新的风格。通常，AdvStyle 是与我们最相关的工作。因此，我们强调关键差异：1) AdvStyle 攻击图像上的风格，而我们使用渐进式攻击方法在多个特征空间上攻击风格；2) AdvStyle 使用相同的任务损失 (分割) 进行攻击和优化；相比之下，我们使用经典的分类损失来攻击风格，同时利用任务损失 (FSL) 来优化整个网络。

## StyleAdv: Meta Style Adversarial Training

