# Discriminative Sample-Guided and Parameter-Efficient Feature Space Adaptation for Cross-Domain Few-Shot Learning

用于跨域小样本学习的区别样本引导和参数高效的特征空间适应

## Abstract

在这篇论文中，我们研究了跨领域小样本分类，这是一个具有挑战性的任务，需要在未见过的领域中利用少量标记样本学习新类别。现有方法虽然在一定程度上有效，但遇到了一些限制，我们通过两项重大改进来解决这些限制。首先，为了解决在小数据集上微调大量参数所带来的过拟合问题，我们引入了一种轻量级的参数高效适应策略。该策略采用了预训练特征的线性转换，显著减少了可训练参数的数量。其次，我们将传统的最近质心分类器替换为区别样本感知损失函数，增强了模型对训练集中类间和类内方差的敏感性，以改进特征空间中的聚类。在 Meta-Dataset 基准测试中的实证评估表明，我们的方法不仅在已见和未见数据集上分别提高了 7.7% 和 5.3% 的准确率，而且在至少约3倍参数效率更高的情况下实现了这一性能，从而达到了跨域小样本学习技术的 SOTA。

## Introduction

深度神经网络在面对充足的训练数据时能够取得显著的性能。然而，在许多应用中由于数据瓶颈 (例如，稀有类别) 或手动标注的成本等原因，收集大型数据集是不可行的。受到这一限制的启发，小样本分类旨在学习分类器来识别每个类只有小量样本的新类。在传统的小样本设置中，新的类别出现在先前见过的领域内，但与先前见过的类别没有重叠。因此，早期的工作侧重于学习识别先前见过的领域内出现的新类别。然而，在现实场景中，更有可能的是新类别将出现在先前未见过的领域中。这个具有挑战性的情景，即在先前未见过的领域中学习新类别，是跨域小样本学习问题所面临的，也是本文的重点所在。

现有方法通常通过首先从大型数据集中学习一组与任务无关的 (即泛化的) 特征来解决这一挑战。然后，这些特征使用一个小型训练集 (称为支持集)，通常每类仅包含五张图像，进行针对特定目标任务的微调。这两个阶段分别称为元训练 (或预训练) 和元测试。随后，对微调模型在单独的测试样本集 (即查询集) 上的性能进行评估，其中的目标是准确地将每个查询样本归类为支持集中所代表的类别之一。然而，正如表 1 所示，现有方法在元测试阶段经常涉及对大量任务特定参数进行微调。这种做法可能会导致过拟合，特别是在数据稀缺的情况下。此外，已经表明，神经网络的较浅层通常包含更通用的特征，可以应用于新任务而无需进行显式微调。尽管如此，许多现有研究方法尝试将整个预训练模型适应目标任务，这在有限的数据情况下可能会增加过拟合的风险。

![image-20240326164047685](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261640817.png)

另一方面，现有的研究通常采用最近质心分类器 (NCC) 来微调任务特定参数和后续的查询分类。NCC 将图像分配给最接近的质心所在的类别，其中质心是属于该类别的特征嵌入的平均值。它鼓励每个嵌入与其相应类别的质心之间的距离比其他类别的质心更近。因此，这些类别在特征嵌入空间中形成了紧密的聚类（参见图 1a）。然而，由于 NCC 对类间方差的关注不足，存在着导致结果聚类不足够分离的风险。这可能导致质心位置过于接近，如图 1a 所示，在查询分类过程中造成混淆。

![image-20240325164200105](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403251659552.png)

受上述启发，如图 2 所示，我们提出采用一组轻量级任务特定参数，将任务无关的特征主干适应到一个未见过的领域中。与先前的工作不同，我们提出采用参数高效的特征线性转换来调整预训练模型，显著减少可训练参数的数量。此外，我们建议改变调整深度，仅微调网络较深层中不太可转移的特征表示，从而进一步减少可训练参数的数量，使其比现有方法更具参数效率 (参见表 1，其中 $d_t = 9, 7$)。此外，我们提议利用支持集中存在的样本信息，来识别具有挑战性的正例（即给定类别的最不相似的正例）或具有挑战性的负例（即给定类别的最相似的负例），以鼓励更好地进行微调时的类内和类间分离，促进特征空间中更好的聚类形成。因此，如图 1b 所示，我们的方法在特征空间中形成了井然有序的聚类，减少了混淆的质心，从而提高了查询分类的准确性。我们通过提出一个简单而有效的流程，推进了小样本学习。我们在标准的跨域小样本分类基准数据集上对我们的方法进行了系统评估，并展示了优于现有最先进方法的性能。

![image-20240325165943154](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403251659367.png)

## Related Work

学习易于适应新任务的任务无关表示对于跨领域泛化的成功至关重要。许多现有方法依赖于元训练期间的监督学习来学习任务无关表示，但这种方法可能导致监督崩溃，其中模型只关注源数据集类别的重要特征，从而忽略了未见类别的语义重要特征。为了规避这种情况，我们的方法采用自监督学习来预训练任务无关特征提取器，确保更广泛地学习超越源数据集的类标签。

在元测试期间，任务无关表示通过支持集进行适应 (或微调) 到目标任务。简单的 CNAPS 和 FLUTE 采用了任务特定的 FiLM 层，这些层被串联到主干网络上，并涉及到用于特征提取器适应的仿射变换，FiLM 参数由元训练的辅助网络估计。与它们不同，我们的方法直接在支持集上学习这种适应，省去了辅助网络的需求。TSA 使用残差适配器，将完整的预训练提取器主干适应到目标任务上，这些适配器并行连接并涉及矩阵乘法。类似地，eTT 和ATTNSCALE 利用视觉提示或缩放矩阵进行任务特定的适应。相比之下，我们的方法通过使用轻量级的线性转换简化了这个过程，将特征适应到目标任务。URT 使用多个特定于域的特征提取器，并具有任务特定的融合机制，这增加了训练成本。相比之下，我们通过一个特征提取器和任务特定参数实现了适应。此外，与许多现有工作不同，我们的方法不是适应整个特征主干，而是专注于适应更深的网络层。最后，我们通过在支持集上采用区别样本感知损失函数，与先前研究中常见的使用 NCC 损失进行微调的方法有所不同。

存在多个现有工作不属于上述讨论的典型任务无关和任务特定分类。例如，ProtoNet 利用类原型来对查询样本进行分类。CTX 通过使用注意力机制创建更符合任务的原型来扩展 ProtoNet。SSA 通过增加支持集数据集来创建更具挑战性的训练样本，改进了 TSA。PMF 通过添加任务采样和学习率选择策略，对目标领域进行了完整的特征主干微调。我们的方法还与这些方法进行了综合性能比较的基准测试。

## Methodology

一个小样本任务通常包含一个支持集 ${\mathcal{S}=\{x_i,y_i\}}_{i=1}^{|S|}$，其中包含 $\left|S\right|$ 个样本和标签对，以及一个查询集 $\mathcal{Q}=\{x_i,y_i\}_{i=1}^{|Q|}$，其中包含 $\left|Q\right|$ 个样本和标签对。在小样本分类中，我们的目标是使用支持集 $\mathcal{S}$ 来学习一个分类器，准确地预测查询集 $\mathcal{Q}$ 中样本的标签。需要注意的是，本文着重研究小样本图像分类问题，即 $x$ 和 $y$ 分别表示图像和其标签。

我们遵循现有工作，并采用两步法来解决这个问题。在第一阶段，我们训练一个特征提取器 $f_{\theta}$，使用一个大型数据集 (称为源数据集) 来学习任务无关的特征表示。在第二阶段，我们首先使用从支持集 $\mathcal{S}$ 中学习到的特定于任务的权重，为从目标数据集中采样的目标任务 $(\mathcal{S},\mathcal{Q})$ ，调整与任务无关的特征。随后，我们使用适应的模型来对查询集 $\mathcal{Q}$ 中的样本进行分类。

神经网络架构：与现有工作一样，我们采用 Vision Transformer (ViT) 模型作为我们的主干架构。

### Task-agnostic representation learning

最近的研究提出利用 DINO 自监督算法来预训练任务无关的特征表示。DINO 专注于从图像裁剪中学习“从全局到局部”的关系，以获得深层特征。然而，我们的方法则借鉴了掩码图像建模（MIM）的新概念，用于预训练特征提取器 $f_{\theta}$。MIM 涉及对图像的某些区域进行掩盖，并提示模型利用未掩盖区域的上下文来重建这些被掩盖的部分。这种方法不仅要求模型推断缺失的视觉信息，还要求推断其出现的上下文，这需要对图像内容有深入的理解，从而促进了学习语义丰富和泛化的特征表示。正如我们结果中所示，这种泛化是学习任务无关的特征表示的关键，它可以轻松地适应新任务。

### Task-specific representation learning

使用 MIM 训练的特征提取器 $f_{\theta}$ 预计能够为更高级的图像识别任务提供良好的起点。然而，当处理来自未见领域的新类别时，这些特征通常需要微调以更好地处理新的情景。

为了将 $f_{\theta}$ 适应到目标任务，我们提出将一组缩放和偏移补偿参数附加到预训练的 ViT 主干上，以学习特征的线性变换。如上所述，与使用基于矩阵或提示的现有方法不同，我们严格将这些偏移量应用为线性变换。具体地，我们只学习缩放 ($\gamma$) 量和偏移 ($\beta$) 量，以将任务无关的特征适应到目标任务中，因此，在元测试期间将可调参数数量减少到模型参数的 0.5%。形式上，在 ViT 中，对于输入 $x \in \mathbb{R}^{(P^2+1) \times e}$，其中 $e$ 是嵌入维度，输出 $y \in \mathbb{R}^{(P^2+1)\times e}$ (也是下一层的输入)，计算公式为：

$y=\gamma\odot x+\beta$

其中，$\gamma\in\mathbb{R}$ 和 $\beta\in\mathbb{R}$ 分别是应用在 $x$ 上的缩放量和偏移量， $\odot$ 表示点积。这种方法从特征分布匹配的概念中获得启示。具体来说，旨在调整特征分布的一阶 (平均值) 和二阶 (方差) 统计量，仅使用每层两个参数即可调整预训练特征到目标数据分布。

我们将这个线性变换应用在 ViT 的层归一化、多层感知机和多头自注意力层上，如图 2a 所示。尽管可以根据需要调整层的选择，但我们选择在实验中调整所有三种类型的层。我们将最终经过重新参数化的任务特定参数的适应后的特征提取器表示为 $f_{\hat{\theta}}$。

![image-20240326172503590](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261725715.png)

改变微调深度。如上所述，最近的工作通常对新任务微调整个主干。然而，在有限数据情况下，我们的方法改变了对预训练模型进行新任务的任务特定适应程度。这种方法通过选择性地微调模型各层的预训练表示，以满足每个任务的具体要求，实现了对新任务的定制适应。具体来说，我们改变了附加到预训练模型上的任务特定参数 $h_{\psi}$ 的深度 $d_t$ (即在目标任务上微调的层的深度)，其中 $0<d_{t}<L$，$\begin{aligned}h_\psi=\{\psi_j,\text{其中 }j=(L-d_t+1),...,12\}\end{aligned}$，$\psi_{j}=\{(\gamma_{m},\beta_{m}),\mathrm{其中 }m=1,...,6\}$。这种方法在元测试阶段战略性地减少了可调参数的数量，如表 1 所详细说明的，旨在进一步减小对新任务的过拟合风险。

### ![image-20240326172537061](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261725182.png)

#### Discriminative sample-guided feature adaptation

考虑到支持集中样本之间的关系，我们旨在为模型提供具有区别的样本引导的监督信号。为此，我们提出利用一个具有区别的样本感知损失函数。与 NCC 类似，我们为支持集中的每个类别分配一个可学习的类代表 (原型)。然而，与 NCC 不同的是，我们将这些原型视为锚点 (用 $A_{\phi}$ 表示)，样本可以被吸引或排斥到这些锚点上，从而学习一个适应任务的嵌入空间。此外，与 NCC 不同的是，NCC 只将给定类别的样本与其类别原型相关联，我们建议使用锚点与支持集中的所有样本相关联。可以表示为：

$l_{A_{\phi}}(X)=\frac{1}{|A|}\sum_{a\in A}\left\{log(1+\sum_{x\in X_{a}^{+}}e^{\alpha(\delta-s(x,a))})+log(1+\sum_{x\in X_{a}^{-}}e^{\alpha(s(x,a)+\delta))}\right\}$

![image-20240326173710262](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261737362.png)

对于一组嵌入向量 $X$ 和一个锚点 $a \in A$，损失函数鼓励特征向量 $x \in X$ 与 $a$ 之间的余弦相似度 $s(x, a)$ 更大 (即大于用户定义的边距 $\delta$)，如果 $a$ 对应于 $x$ 所属的类别的锚点 (表示为 $\mathbf{x}\in X_{a}^{+}$)，或者更小 (即小于 $- \delta$)，如果 $x$ 属于不同的类别 (表示为 $\mathbf{x}\in X_{a}^{-}$)。$\alpha > 0$ 是用户定义的缩放因子。$L_{A_\phi}(X)$ 被称为代理锚点损失。

具体到我们的工作是通过考虑支持集中存在的样本信息来修改特征空间的方式，如图 3 所示。对于给定的锚点 $a \in A$，它试图将 $a$ 及其最具挑战性的正例  (例如，图 3a 中的 $a_r$ 和 $r_3$) 拉近。类似地，它试图将 $a$ 及其最具挑战性的负例 (例如，图 3b 中的 $a_r$ 和 $b_3$) 推远。当正的特征向量远离 $a$ 时，梯度更大 (线条更粗)，而当负的特征向量接近 $a$ 时，梯度也更大。通过这种方式，方程 2 考虑了每个样本的相对难度 (困难度)，根据特征嵌入空间中的类内和类间变化来确定应用于每个样本的拉力和推力的相对强度。正如我们的结果所示，这种方差引导的梯度相比传统的 NCC 提供了更好的微调监督信号。

![image-20240325153903922](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403251700428.png)

### Feature fusion

已经观察到网络较浅层的特征比较深层的特征更容易迁移到未见领域。然而，现有的工作仅使用模型的最后一层的特征来表示图像，即特征深度 $d_f = 1$。与它们相反，我们从 ViT 的最后 $d_f > 1$ 层提取 $[cls]$ 嵌入，并将它们连接起来形成输入图像的最终特征嵌入，如下所示：

$Z=concat(z_L,z_{L-1},...,z_{L-d_f+1})$

其中，$z_L$ 是第 $L$ 层的图像的 $[cls]$ 嵌入输出，$d_f > 1$ 是一个超参数，$z \in \mathbb{R}^{dim}$，$Z~\in~\mathbb{R}^{h*dim}$。尽管这种直接的融合策略不需要像一些现有的特征融合策略那样进行额外的训练，我们观察到当增加融合深度时，性能显著提高。

### Query classification

在特征空间适应之后，我们将适应后的特征提取器 $f_{\hat{\theta}}$ 与一个最近质心分类器 (NCC) 结合起来对查询样本进行分类。在 NCC 中，对于支持集中的每个类别 $n$，计算一个原型 $c_n$，定义为属于该类别的所有特征表示的平均值，即:

$c_n=\frac1{|S_n|}\sum_{(x,y)\in S_n}f_{\hat{\theta}}(x),\quad n=1,...,N$

![image-20240326175845418](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261758511.png)

在这里，$(x, y) \in S_n$ 表示支持类别 $S_n$ 中特征嵌入及其相应的标签对。为了对样本 $x_q$ 进行分类，我们使用余弦相似度作为距离度量 $d(f_{\hat{\theta}}(x_{q}),c_{n})$，将 $x_q$ 分配给最近的质心 $c_n$ 所属的类别。

## Experiments

### Experimental Settings

数据集：我们使用标准的跨域基准数据集 Meta-Dataset。它包含来自 13 个不同数据集的图像。我们遵循标准协议进行以下实验：1) 多领域学习 (MDL)，使用 Meta-Dataset 中八个数据集的训练集进行预训练；2) 单领域学习 (SDL)，只使用 ImageNet 的训练集进行预训练。为了进行公平比较，我们还遵循 [16] 中的单领域学习与额外数据 (SDL-E) 设置，其中使用整个 ImageNet 数据集进行预训练。更多细节请参考附录。

评估：我们从每个数据集的测试集中随机抽取 600 个 $N-way-K-shot$ 任务，并报告平均准确率和 95% 的置信得分。这里，$N$ 表示类别的数量，$K$ 表示任务中每个类别的示例数量，惯例是随机均匀抽样 $N$、$K$ 以及查询图像的数量 (更多细节请参考 [32] 的附录.3)。我们在 MDL、SDL 和 SDL-E 设置下评估 Meta-Dataset。

架构：我们将实验限制在标准的 ViT-small 架构中。虽然早期基于 ResNet 的工作将输入图像调整为 84×84 像素，但最近基于 ViT 的工作通常将图像调整为 224×224 像素以适应 ViT 架构。遵循这一趋势，我们也采用相同的图像分辨率。然而，值得注意的是，更高的图像分辨率可能为模型提供更丰富的视觉信息，从而可能影响分类性能。因此，我们在报告结果时包含了主干架构的细节，以便透明地比较各种方法。

预训练：我们遵循 [38] 中提出的策略，并大部分保持其工作中报告的超参数设置。我们使用批量大小为 128，800 个 epochs 和 4 个 Nvidia A100 GPU，每个 GPU 具有 80GB 内存，用于预训练。更多细节请参考附录。

微调：我们通过实验确定了超参数的值，其中 $\delta = 0.1$，$\alpha = 32$ 和 $d_f = 4$ 在跨域中实现了最佳性能。$\gamma$ 和 $\beta$ 参数使用常量值 1 和 0 进行初始化，即没有任何随机性，确保我们的结果的可复现性。我们使用两个单独的 NAdam 优化器，其中 $h_\psi$ 的学习率为 0.005，$A_\phi$ 的学习率为 5。我们实验发现，这种学习率组合在大多数任务中效果良好。在单个 Nvidia A100 GPU 上进行 80 次迭代进行微调，该 GPU 具有 80GB 内存。有关超参数的更多详细信息，请参阅附录中的章节。最后，我们使用 $d_t = 7$ 进行在预训练期间已见的领域 (领域内) 的微调，使用 $d_t = 9$ 进行对先前未见的领域 (领域外) 进行微调，因为它们在各个领域中提供了最佳的平均结果。第 6 节对此选择进行了更多讨论。

## Main Results

### Comparison to state-of-the-art methods

从现在开始，我们将我们的方法称为 DIPA，即具有区别样本引导和参数高效适应。我们在 Meta-Dataset 上评估了在 MDL、SDL 和 SDL-E 设置下预训练的特征提取器，并将其与现有的最新方法进行比较，结果列在表 2 中。为了便于公平比较，考虑到先前研究中的不同的元 (或预) 训练策略和主干架构，我们将这些细节与结果一起包括在内。表格分为两个部分：一个是针对领域内 (已见) 数据集准确率的部分，另一个是针对领域外 (未见) 数据集准确率的部分，包括它们的总体平均值。此外，我们还包括了一个针对通常未见领域的平均准确率的列，因为一些先前的研究并未报告我们工作中考虑的所有未见领域的结果。

![image-20240326181121799](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261811945.png)

多领域特征提取器。在表 2 中 (行 A0-A6)，我们对比了仅在 MDL 设置下进行元 (或预) 训练的最新方法。值得注意的是，DIPA 在所有常见的已见和未见领域 (10个中的10个) 中均优于 eTT，后者采用了自监督预训练，并且参数效率高达 32.5 倍 (参见表 1，$d_t = 7$ 和 $9$)。与使用监督元训练的特征提取器 $f_\theta$ 的方法（例如 Simple CNAPS、URT 、FLUTE、TSA 和 SSA）相比，DIPA 在大多数领域中表现更优，尤其是在 5 个未见领域中有 4 个领先。在未见领域中提高性能是一个重大挑战，因为已见和未见领域之间存在巨大差异，新任务的标记样本有限。DIPA 通过采用轻量级线性转换进行特征适应，以及具有区别样本引导的损失函数来解决这个问题。尽管 TSA+SSA 也使用了MixStyle 类似的增强策略并取得了有竞争性结果，但 DIPA 在大多数未见领域中实现了更好的性能，而无需进行此类增强，同时参数效率高达 24.7 倍 (见表1)。具体而言，DIPA 在交通标志 (+6.4)、MS-COCO (+6.7)、CIFAR-10(+4.5) 和 CIFAR-100 (+10.4) 等方面显着超过了 TSA+SSA。

具有额外预训练的多领域特征提取器。在表 2 (行 B0-B2) 中，我们将 DIPA 与 PMF 和 ATTNSCALE 进行比较，它们在 MDL 设置下评估模型，并使用 SDL-E 进行自监督预训练。请注意，与 DIPA 和 ATTNSCALE 不同，PMF 还使用 MDL 进行元训练。DIPA 胜过 ATTNSCALE，在未见领域中的性能提高了 2.9%，在已见领域中提高了 2.7%，而且参数效率高达 4.3 倍 (见表 1)。尽管 PMF 包括额外的元训练阶段和任务特定的学习率选择，但 DIPA 的未见领域性能超过 PMF 3.3%。这种增强的性能是通过显着的计算效率实现的，因为 DIPA 只需要两个阶段：预训练和微调，从而消除了额外的元训练或学习率选择的需要。此外，DIPA 的微调过程非常高效，仅使用了模型参数的  0.08%，与 PMF 的 100% 参数利用率形成鲜明对比 (见表 1)。

单领域特征提取器。我们还使用仅在 ImageNet 域上进行训练的特征提取器进行评估，称为单领域学习 (SDL) 设置。与多领域场景相比，SDL 设置面临更大的挑战，因为模型仅暴露于一个训练域，但在多个域上进行评估，包括 ImageNet 的测试集和其他多样的领域。在表 2 (行 C0-C3) 中，我们将我们的方法与现有方法 (ProtoNet、CTX 和 TSA)进行比较，这些方法在此设置下发布了结果。我们的方法在所有 13 个领域中均超越了这些方法。值得注意的是，我们的模型利用了自监督预训练以及与这里比较的模型架构明显不同的主干架构，这可能会影响到此比较的公平性。尽管如此，我们的方法仍然表现出显著的性能提升，分别对已见、未见 (全部) 和所有领域的改进分别为 7.7%、4.7% 和 5%。

具有额外预训练的单领域特征提取器。在表 2 (行 D0-D1) 中，我们将 DIPA 与最新的最先进方法 PMF 进行比较。在这里，PMF 使用 SDL-E 进行预训练，并使用额外的 SDL 阶段进行元训练，这是 DIPA 中未使用的一个步骤。尽管缺少这个元训练阶段，DIPA 在所有 13 个领域中都表现出优异的性能。具体来说，在已见领域中，它显示出 2.6% 的改进，在常见的未见领域中为 4.4%，在所有领域中为 6.5%。这种性能是在不需要额外的计算步骤或对整个主干进行广泛微调的情况下实现的，而 PMF 则需要这些步骤 (请参阅表1中的详细信息)。总的来说，我们的结果表明，DIPA 在已见和未见领域内的跨域场景中显着优于最先进的方法，同时更具参数效率。

## Additional Analysis

在本节中，我们进行消融研究，评估我们方法中的每个步骤，并验证它们对改善小样本分类性能的影响。

### Impact of varying the fine-tuning and query classification approaches

首先，我们在表 3 (行 A0 和 A2) 中比较了我们的微调策略 $l_{A_\phi}$ 与传统的基于均值嵌入的 NCC ($NCC_{mean}$)。在这里，采用 $l_{A_\phi}$ 损失进行微调显著提高了分类性能，在已见领域中提高了高达 2.8%，在未见领域中提高了 1.6%，相比之下使用 $NCC_{mean}$。此外，在聚类形成方面，对于 ImageNet 数据集，$l_{A_\phi}$ 在类间距离、类内距离和轮廓系数方面均比 NCC 表现更好，分别提高了 1%、6% 和 1%。

接下来，我们将我们的查询分类策略 $NCC_mean$ 与另一种替代方案进行比较。如上所述，在微调过程中，DIPA 学习了一组锚点 $A_{\phi}$，这些锚点提供了强有力的监督，形成了良好分离且紧凑的聚类 (参见图1b)。这为使用微调后的锚点代替 $NCC_{mean}$ 中使用的均值类中心进行查询分类提供了机会。我们将这种变体表示为 $NCC_{A_{\phi}}$。然而，虽然锚点 $A_{\phi}$ 为聚类形成提供了强有力的监督信号，但我们观察到在某些情况下，锚点与均值中心之间存在小的偏移（参见附录图 ??），这表明在推断期间，概括紧凑聚类的均值类中心可能是更具代表性的类描述符。我们的结果也支持了这一假设，与 $l_{A_{\phi}}+NCC_{A_{\phi}}$ 相比，将 $A_{\phi}$ 与 $NCC_{mean}$ 结合使用在已见和未见领域分别提高了 3.9% 和 5.3% 的性能。因此，我们在微调过程中使用 $A_{\phi}$ 锚点进行聚类形成，并随后使用这些定义良好的聚类在推断期间获取查询分类的均值类中心。

![image-20240326184031137](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261840266.png)

### Impact of varying the number of tuned layers

我们研究了在 $f_θ$ 中变化调整层数的数量对结果的影响。图 4 展示了在 Meta-Dataset 中每个数据集的平均准确率随着调整层数 $d_t$ 的变化情况，其中 $0 ≤ d_t ≤ L$，对于 ViT-small，$L = 12$。从结果中我们观察到以下几点： 1) 没有普遍适用于所有领域的能够提供最佳结果的 $d_t$ 值； 2) 存在一个普遍趋势，即相对不太具有挑战性的领域 (如VGG Flower，CIFAR-10等) 在较小的 $d_t$ 值时报告较高的准确性。相反，相对更具挑战性的领域，如 Quickdraw 和 Traffic Sign，在较大的 $d_t$ 值时报告较高的准确性； 3) 大多数领域在 $d_t < 12$ 时报告较高的准确性，即我们的方法不需要将任务特定的参数附加到模型的每一层 (如 TSA 和 eTT 中所示)，也不需要微调整个主干网络 (如 PMF 中所示）。这进一步减少了可训练参数的数量。例如，如表 1 所示，通过将 $d_t$ 从 12 减小到 7，我们将参数数量减少了 0.2%。

![image-20240326183610625](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261836762.png)

图 4 显示，根据每个领域自定义深度 $d_t$ 可以获得最佳性能。然而，这种定制增加了我们模型的额外用户定义参数。为了简化，我们简化我们的方法，只使用两个 $d_t$ 值：对于已知领域，$d_t = 7$，对于未知领域，$d_t = 9$，基于图 5 中所示的平均性能峰值。此外，选择较高的 $d_t$ 值用于未知领域与直觉相符，即通过调整更多层进行更广泛的适应通常在处理未知领域时是有益的。

### Impact of varying the feature fusion depth

我们通过改变特征融合深度 $d_f$ 来比较少样本分类的性能变化，并在表 4 中报告平均结果。首先，我们注意到即使在 $d_f = 1$ 时，我们的方法也比现有方法表现出显著优势。接下来，我们观察到随着在 DIPA 中增加 $d_f$，平均准确率通常呈递增趋势，直至 $d_f = 4, 6$，验证了我们融合多个层特征的选择。然而，随后性能呈逐渐下降的趋势。一个可能的原因是将更多的浅层特征 (包含更通用的模式) 结合在一起会导致模型忽视较深层中重要的特定领域特征。这也反映在结果中，其中 $d_f = 8, 12$ 的准确率甚至低于 $d_f = 1, 2$。

### Impact of Pre-training

在表 5 中，我们评估了使用 MIM 进行预训练的影响，与现有方法中更常用的 DINO 预训练相比。对于我们的实验，我们利用了 SDL-E 设置，利用现成的 DINO 检查点。首先，我们将具有 DINO 预训练的 DIPA 模型与 DINO-based PMF 进行比较，在 SDL-E 设置中代表了最先进的技术。如表 5 的前两行所示，DIPA 相比 PMF 提高了 5.8% 的性能，即使没有我们首选的自监督预训练任务，也表明了其有效性。接下来，我们用基于 MIM 的特征提取器替换了基于 DINO 的特征提取器 (参见表 5 第 3 行)。这一变化导致准确率进一步提高，比 PMF 提高了 6.5%，验证了我们选择的预训练算法的有效性。

![image-20240326184046815](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403261840931.png)

## Conclusions and Limitations

在这项研究中，我们探索了用于小样本分类任务的深度网络的高效自适应方法。我们的方法利用极轻量级的线性变换，通过一个针对样本的区分性损失函数进行优化，以便利于利用有限数量的标记样本学习新类别和领域。该方法在具有挑战性的 Meta-Dataset 基准测试中实现了最先进的性能，同时确保了参数的高效性。然而，我们的方法也存在一些局限性。

在我们当前的方法中，我们将一个固定的线性变换应用于 ViT 的每一层。未来的改进可能会使这些变换能够灵活地逐层定义，以满足目标任务的特定要求。此外，未来的研究可以探索针对每个数据集和任务定制的最佳调整深度，而不仅仅是将调整深度限制为仅适用于已见和未见数据集的两个值，这可能导致次优结果。