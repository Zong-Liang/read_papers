# SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation

SAMUS：将 SAM 模型用于临床友好的和通用的超声图像分割

## Abstract

Segment Anything Model (SAM)，作为一个卓越的通用图像分割模型，在医学图像分割领域近来引起了相当大的关注。尽管 SAM 在自然图像上表现出了显著的性能，但当面对医学图像，特别是那些涉及低对比度、模糊边界、复杂形状和微小尺寸对象的图像时，它往往表现出显著的性能下降和有限的泛化能力。在本文中，我们提出了 SAMUS，一个专门针对超声图像分割的通用模型。与以前基于 SAM 的通用模型不同，SAMUS 不仅追求更好的泛化能力，还降低了部署成本，使其更适用于临床应用。具体来说，基于 SAM，引入了一个并行的 CNN 分支，通过跨分支注意力将局部特征注入到 ViT 编码器中，以实现更好的医学图像分割。然后，开发了位置适配器和特征适配器，将 SAM 从自然领域适应到医学领域，并从需要大尺寸输入 (1024×1024) 转变为小尺寸输入 (256×256)，以实现更友好的临床部署。我们收集了一个包含约 30k 张图像和 69k 个掩码的综合超声数据集，涵盖了六个对象类别，用于验证。大量的比较实验表明，SAMUS 在特定任务评估和泛化评估下优于最先进的特定任务模型和通用基础模型。此外，SAMUS 可部署在入门级 GPU 上，因为它已经摆脱了长序列编码的限制。代码、数据和模型将发布在 https://github.com/xianlin7/SAMUS 上。

## Introduction

医学图像分割是一项至关重要的技术，用于识别和突出显示医学图像中的特定器官、组织和病变，它是计算机辅助诊断系统的一个组成部分。许多深度学习模型已经被提出用于自动医学图像分割，展示了巨大的潜力。然而，这些模型都是针对特定对象设计的，当应用于其他对象时需要重新训练，这给临床使用带来了很大的不便。

作为视觉分割的多功能基础模型，SAM 模型因其在各种对象上的显著分割能力和强大的零样本泛化能力而受到了相当大的赞誉。根据用户提示，包括点、边界框和粗略掩膜，SAM 能够对应地分割出对象。因此，通过简单的提示，SAM 可以轻松地适应各种分割应用。这种范式使得将多个个体医学图像分割任务整合到一个统一的框架中成为可能 (即通用模型)，极大地促进了临床部署。

尽管研究人员构建了迄今为止最大的数据集 (即 SA1B)，但由于可靠的临床注释稀缺，SAM 在医学领域遇到了快速的性能下降。一些基础模型已经被提出，通过在医学数据集上调整 SAM 来使 SAM 适应医学图像分割。然而，与 SAM 一样，它们在进行特征建模之前对输入图像执行了不重叠的 16× 标记化，这破坏了用于识别小目标和边界的局部信息，使它们难以分割具有复杂/线状形状、弱边界、小尺寸或低对比度的临床对象。此外，它们中的大多数需要输入大小为 1024×1024，这会由于生成的长输入序列而对 GPU 消耗造成重大负担。

在本文中，我们提出了 SAMUS，将 SAM 的出色分割性能和强大的泛化能力转移到医学图像分割领域，并降低了计算复杂度。SAMUS 继承了 SAM 的 ViT 图像编码器、提示编码器和掩码解码器，并针对图像编码器进行了定制设计。首先，我们通过减小输入大小来缩短 ViT 分支的序列长度，以降低计算复杂度。然后，开发了特征适配器和位置适配器，以将 ViT 图像编码器从自然领域微调到医学领域。为了补充 ViT 图像编码器中的局部（即低级）信息，我们引入了一个并行 CNN 分支图像编码器，与 ViT 分支同时运行，并提出了一个跨分支注意力模块，使 ViT 分支中的每个补丁能够吸收来自 CNN 分支的局部信息。此外，我们构建了一个名为 US30K 的大型超声数据集，以全面评估 SAMUS 的有效性。实验结果表明，SAMUS 在特定任务和通用医学图像分割中均优于最先进的方法。更重要的是，与 SAM 相比，SAMUS 表现出了显著的泛化能力，同时大幅降低了训练成本。贡献可以总结如下：

- SAMUS 是一个通用超声图像分割的基础模型，与 SAM 相比，需要较少的 GPU 资源。
- 一个 CNN 分支图像编码器和一个跨分支注意力模块，有效地补充了 SAM 的 ViT 图像编码器的局部信息。
- 一个特征适配器和一个位置适配器，用于微调 ViT 分支图像编码器，进一步优化 SAM 以适应医学领域。
- 一个大型超声数据集，包括 30,106 张图像和 68,570 个掩码，以全面评估 SAMUS 的有效性。

## Related Works

### Visual Tuning

随着计算机视觉基础模型的惊人发展，一系列视觉调整方法已被提出，以将这些基础模型调整到下游任务中。通常，最近的视觉调整方法可以分为五大类，包括微调、参数调整、重映射调整、提示调整和适应调整。具体来说，微调方法涉及调整预训练模型的整个参数集或选择性地微调预训练模型的特定部分。参数调整方法直接修改模型参数的权重或偏差。重映射方法通过知识蒸馏、基于权重的重映射或基于架构的重映射将从预训练模型中学到的信息转移到下游模型。提示调整通过将一组可学习参数与输入结合，或设计一个子网络来生成视觉提示，引入下游任务的知识。适配器调整是最广泛采用的策略，通过将额外的可学习参数与冻结的预训练模型结合起来，促进了对下游任务的学习。

### Adapt SAM to Medical Image Segmentation

SAM 在自然图像中表现出了显著的性能，但在一些医学图像分割任务中遇到了困难，特别是在具有复杂形状、模糊边界、小尺寸或低对比度的对象上。为了弥合这一差距，并使 SAM 能够有效地适应医学图像领域，研究人员已经提出了几种方法来使用有限的下游医学数据集调整 SAM。MedSAM 通过冻结图像编码器和提示编码器，专注于调整 SAM 的掩码解码器，以可接受的成本在医学图像上对 SAM 进行训练。SAMed 在图像编码器上应用低秩 (LoRA) 策略，以更低的计算成本调整 SAM，使其更适用于医学图像分割。MSA 在 ViT 图像编码器的每个变压器层上采用两个 downReLU-up 适配器，引入了任务特定信息。如图 1 所示，与当前基于 SAM 的基础模型相比，所提出的 SAMUS 更注重补充局部特征和降低 GPU 消耗，这对于在临床场景中进行准确和易于部署的医学图像分割至关重要。

![image-20240313092922652](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403131045765.png)

## Methods

### Overview

如图 2 所示，SAMUS 的整体架构继承自 SAM，保留了提示编码器和掩码解码器的结构和参数，没有进行任何调整。相比之下，图像编码器经过精心修改，以解决局部特征不足和计算内存消耗过大的挑战，使其更适用于临床友好的分割。主要修改包括减小输入大小、重叠的补丁嵌入、向 ViT 分支引入适配器、添加 CNN 分支和引入跨分支注意力 (CBA)。具体来说，输入空间分辨率从 1024×1024 像素缩小到 256×256 像素，由于变换器中较短的输入序列，导致 GPU 内存成本大幅降低。重叠的补丁嵌入使用与 SAM 中的补丁嵌入相同的参数，而其补丁步幅为原始步幅的一半，很好地保留了来自补丁边界的信息。ViT 分支中的适配器包括一个位置适配器和五个特征适配器。位置适配器是为了适应由于较小的输入大小而在较短序列中的全局位置嵌入。第一个特征适配器遵循重叠的补丁嵌入，将输入特征与预训练的 ViT 图像编码器所需的特征分布进行对齐。其余的特征适配器附加在全局变换器中前向网络的残差连接上，以微调预训练的图像编码器。在 CNN 分支方面，它与 ViT 分支并行，通过 CBA 模块向后者提供补充的局部信息，该模块将 ViT 分支特征作为查询，并与来自 CNN 分支的特征建立全局依赖关系。需要注意的是，CBA 仅集成到每个全局变换器中。最后，两个分支的输出被合并为 SAMUS 的最终图像特征嵌入。

![image-20240313092733763](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403130927886.png)

### Adapters in the ViT Branch

为了促进 SAM 的训练图像编码器（即 ViT 分支）向更小的输入尺寸和医学图像领域的泛化，我们引入了一个位置适配器和五个特征适配器。这些适配器可以有效调整 ViT 分支，同时只需要更少的参数。具体来说，位置适配器负责调整位置嵌入以匹配嵌入序列的分辨率。它首先通过步幅和核大小为 2 的最大池化对位置嵌入进行降采样，实现与嵌入序列相同的分辨率。随后，应用一个核大小为 3×3 的卷积操作来调整位置嵌入，进一步帮助 ViT 分支更好地处理更小的输入。所有特征适配器具有相同的结构，包括三个组件：一个下线性投影、一个激活函数和一个上线性投影。每个特征适配器的过程可以描述为：

$\mathcal{A}(x)=\mathcal{G}(xE_d)E_u$

其中，$\mathcal{G}$ 表示 GELU 激活函数，$E_{d}\in\mathbb{R}^{\frac{d}{4}\times d}$ 和 $E_{u}\in\mathbb{R}^{\frac{d}{4}\times d}$ 是投影矩阵，$d$ 是特征嵌入的维度。通过这些简单的操作，特征适配器使 ViT 分支能够更好地适应医学图像领域的特征分布。

### The CNN Branch

CNN 分支由顺序连接的卷积池化块组成。具体来说，输入首先通过单个卷积块，然后通过三个卷积池化块进行处理。接下来，CNN 分支中的特征图与 ViT 分支的特征图具有相同的空间分辨率。在 CNN 分支的其余部分中，这样的单个卷积块被连续重复四次。更多细节请参见图 2。CNN 分支的这种简约轻量设计旨在防止训练过程中的过拟合。

### Cross-branch Attention

跨分支注意力（CBA）模块在 CNN 分支和 ViT 分支之间创建了一个桥梁，进一步通过 ViT 分支补充缺失的局部特征。对于来自 ViT 分支 $F_v$ 和 CNN 分支 $F_c$ 的特征图对，单头的跨分支注意力可以表示为：

$\mathcal{F}(F_v,F_c)=(\mathcal{S}(\frac{F_vE_q(F_cE_k)^T}{\sqrt{d_m}})+R)(F_cE_v)$

其中，$S$ 表示 Softmax 函数。$E_q\in\mathbb{R}^{d×d_m}$，$E_k\in\mathbb{R}^{d×d_m}$ 和 $E_v\in\mathbb{R}^{d×d_m}$ 是用于将 $F_c$ 和 $F_v$ 投影到不同特征子空间的可学习权重矩阵。$R\in\mathbb{R}^{hw\times hw}$ 是相对位置嵌入，$d_m$ 是 CBA 的维度。CBA 的最终输出是这种单头注意力的线性组合。

### Training Strategies

在训练之前，SAMUS 使用在 SA-1B 上训练的权重初始化从 SAM 继承的参数。其余参数随机初始化。在训练过程中，只有适配器、CNN 分支和 CBA 模块的参数被更新，其他参数保持冻结。训练过程使用组合损失函数进行监督，包括 Dice 损失和二元交叉熵损失。为了方便使用，SAMUS 只使用最简单的正点提示。我们通过在标签的前景区域随机采样一个点来模仿专家提供提示的过程。SAMUS 由 Adam 优化器训练，初始学习率为 0.0001，批大小为 8，共进行 200 个epoch。

## Experiments

### Datasets

为了全面评估 SAMUS 的有效性，我们构建了一个名为 US30K 的大型超声数据集，如表 1 所总结，包含来自七个公开可用数据集的数据，包括 TN3K、DDTI、TG3K、BUSI、UDIAT、CAMUS 和 HMCQU。TN3K 和 TG3K 的数据按照 TRFE 进行划分为训练、验证和测试集。BUSI 被随机分为 7:1:2 用于训练、验证和测试。CAMUS 根据挑战首先被划分为一个训练集和一个测试集。然后，我们从训练集中随机选择 10% 的患者来验证模型，其余数据作为最终的训练数据。为了评估不同模型的泛化能力，US30K 中的其他数据集在训练和验证过程中是看不见的。为了评估SAMUS 与最先进的特定任务方法的分割性能和泛化能力，我们分别实现了几种 SOTA 方法，并在 TN3K、BUSI 和 CAMUS 数据集上进行训练。此外，通过在整个 US30K 数据集上训练它们，并在单独的任务上评估它们，进行了 SAMUS 与其他基础模型之间的比较。

![image-20240313094917637](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403131045403.png)

### Compare with SOTA Task-specific Methods

比较方法：选择了十二种最先进的特定任务方法进行比较，涵盖了基于 CNN、基于 Transformer 和 CNN-Transformer 混合方法。基于 CNN 的方法包括 U-Net、CPFNet、CA-Net、CE-Net 和 AAU-Net。基于 Transformer的方法包括 SwinUnet、SETR 和 MISSFormer。基于 CNN-Transformer 的混合方法包括 TransUNet、TransFuse、FAT-Net 和 H2Former。

定量结果：在 TN3K、BUSI、CAMUS-LV、CAMUS-MYO 和 CAMUS-LA 上，不同特定任务方法的定量结果如表 2  所总结。在这些最先进的方法中，H2Former 在 TN3K 和 CAMUS-MYO 上取得了最佳性能，平均 Dice 分数分别为82.48% 和 87.31%。TransUnet、CA-Net 和 FATNet 在 BUSI、CAMUS-LV 和 CAMUS-LA 上分别取得了最佳性能，平均 Dice 分数为 82.22%、93.59% 和 91.55%。相比之下，SAMUS 在所有五个任务（包括 TN3K、BUSI、CAMUS-LV、CAMUS-MYO 和 CAMUS-LA）上均取得了更好的性能，平均 Dice 分数分别为 84.45%、85.77%、93.73%、87.46% 和 91.58%。这验证了 SAMUS 将 SAM 调整到医学图像领域的有效性。

![image-20240313101747577](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403131046119.png)

定性结果：图 4 展示了不同方法（包括 U-Net、AAU-Net、MISSFormer、H2Former 和 SAMUS）的定性分割结果。从视觉上看，超声图像的分割面临着挑战，因为其低对比度、不均匀特征和模糊的对象边界。现有方法在准确区分目标和背景方面存在困难，导致大量的假阴性和或假阳性。相比之下，SAMUS 在保留目标区域的完整性和减少假阳性方面表现出了优越性。这归因于 SAM 框架的固有优势，以及 SAMUS 中引入的特定调整和设计。

![image-20240313102214868](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403131022014.png)

泛化能力：图 3 中展示了不同特定任务方法泛化性能的定量比较。在比较方法中，H2Former、TransUNet 和 TransFuse 在 DDTI、UDIAT 和 HMC-QU 上取得了最佳性能。相比之下，SAMUS 在每个数据集上都超过了最佳比较方法，平均 Dice 分数分别增加了 7.06%、12.22% 和 7.42%。比较可见和不可见数据集之间的性能，相对于其他比较方法，SAMUS 在三个不同的分割任务中遭遇的性能下降最少。一个有趣的观察是，在乳腺癌分割任务中，SAMUS 在不可见数据集（即 UDIAT）上的性能甚至比可见数据集（即 BUSI）上的最佳比较方法还要好。这展示了SAMUS 在处理未知领域时的出色泛化能力，展示了其在各种医学图像分割场景中的稳健性和适应性。

![image-20240313104706253](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403131047374.png)

### Compare with SOTA Foundation Models

比较方法：我们选择了四种最先进的基础模型进行比较，包括原始的 SAM、MedSAM、SAMed 和 MSA。

定量结果：为了验证 SAMUS 作为一个基础模型在不同下游任务上的通用性能，我们在 US30K 数据集上对基础模型进行比较。如表 8 所总结，SAM，即在 SA-1B 上训练的模型，在没有调整的情况下在医学图像分割上表现出显著的性能下降。通过简单地对基于 US30K 数据集的 SAM 的 mask 解码器进行微调，MedSAM 显著改善了 SAM 的性能。在比较的基础模型中，MAS 是表现最好的模型，通过对 SAM 进行微调，平均 Dice 分数分别在 TN3K、BUSI、CAMUS-LV、CAMUS-MYO 和 CAMUS-LA 上增加了 53.08%、27.65%、62.77%、53.05% 和 74.52%。与 MSA 相比，SAMUS 在以上五个数据集上始终取得了显著的改进，平均 Dice 分数分别为83.05%、84.54%、91.13%、83.11% 和 92%。这验证了 SAMUS 中 CNN 分支和 CBA 模块在补充关键的局部信息方面的有效性，这对于医学图像分割至关重要。

![image-20240313102054899](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403131047036.png)

定性结果：图 5 展示了不同基础模型（包括SAM、MedSAM、SAMed、MSA 和 SAMUS）的定性分割结果。在未调整医学图像的情况下，SAM 完全失去了分割一切的能力。通过将调整方法应用于 SAM，MedSAM、SAMed 和 MSA 可以在一定程度上恢复 SAM 的分割能力。然而，它们仍然在超声图像中挣扎以准确勾勒分割边界，导致大量的假阴性和假阳性。相比之下，SAMUS 表现出优越的性能，能够准确地定位分割边界，即使是低对比度的边界也能做到。这与通过将图像编码器与本地信息进行补充有关的分析一致，特别是在医学图像分割中保持边界/形状的完整性方面。

泛化能力：图 6 总结了不同基础模型在未知领域上的比较。总的来说，基于 US30K 训练的基础模型在医学图像分割任务中的泛化性能远远优于原始的 SAM。在三组分割任务（即甲状腺结节分割、乳腺癌分割和心肌分割）中，所有基础模型在心肌分割上都遭遇了严重的性能下降，并且在乳腺癌分割上具有良好的泛化能力。SAMUS 在所有三个未知数据集上始终取得了最佳性能，导致甲状腺结节、乳腺癌和心肌分割的优越 Dice 分数分别为 66.78%、78.06% 和 56.77%。这突显了 SAMUS 的出色泛化能力，在未知领域上始终优于其他基础模型。

![image-20240313102441541](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403131047223.png)

部署成本：我们对 SAMUS 和其他基础模型的部署效率进行了全面评估，包括 GPU 内存消耗、模型参数、计算复杂度、推断速度、分割性能和泛化性能。为了方便比较，在训练过程中将批量大小设置为 1 时测试 GPU 内存，并以千兆字节（即 G）表示。计算复杂度和推断速度以每秒浮点操作数（即 GFLOPs）和每秒帧数（即 FPS）来衡量。分割性能以所有可见数据集的平均 Dice 分数来衡量，泛化性能则根据所有未见数据集的平均 Dice 分数进行评估。所有上述指标都经过归一化处理，并以雷达图的形式显示，如图 7 所示。在比较模型中，SAMed 展示了最低的 GPU 内存消耗、模型参数、计算复杂度和最快的推断速度。然而，其分割和泛化性能均低于 MSA 和 SAMUS。尽管 SAMUS 的参数比其他模型更多，但其 GPU 内存消耗和计算复杂度仅次于最低，并且推断速度仅次于最快，这表明 SAMUS 是一个更适合临床的模型。此外，SAMUS 的部署性能与最易部署方法（即 SAMed）非常接近，但分割和泛化性能要好得多。

![image-20240313102500783](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main//202403131025883.png)

### Ablation Study

SAMUS 中的四个组件，包括 CNN 分支、CBA、特征适配器和位置适配器，依次引入到原始的 SAM 中，并在 TN3K 和 BUSI 数据集上进行评估。如表 9 所总结的，SAMUS 的任何一个组件都能有效提高 SAM 在医学任务上的分割性能和泛化能力。即使是简单的位置适配器，在 TN3K、DDTI、BUSI 和 UDIAT 上分别将 SAM 的 Dice 提高了50.6%、38.1%、26.77% 和 30.54%。通过引入局部特征，CNN 分支的性能改善要比位置适配器更为显著。此外，仅仅将 CNN 分支和 ViT 分支的输出进行融合并不是最佳选择。引入 CBA 可以进一步促进对局部特征的探索，从而使 Dice 平均增加了 1.48% 和 2.11%。通过将所有四个组件组合起来，SAMUS 实现了最佳的分割性能和泛化能力。

![image-20240313102555814](https://cdn.jsdelivr.net/gh/ZL85/ImageBed@main/202403131047220.png)

## Conclusion

在本文中，我们提出了 SAMUS，这是一个源自 SAM 的通用基础模型，用于临床友好和具有普适性的超声图像分割。具体来说，我们提出了一个并行 CNN 分支图像编码器，一个特征适配器，一个位置适配器和一个跨分支注意力模块，以丰富小尺寸对象和边界区域的特征，同时降低 GPU 消耗。此外，我们构建了一个大型超声图像数据集 US30K，包括 30,106 张图像和 68,570 个掩模，用于评估和潜在的临床应用。在可见和未见领域的实验中，我们展示了 SAMUS 出色的分割能力和强大的泛化能力。此外，SAMUS 的 GPU 内存消耗仅为训练整个 SAM 所需内存的28%，SAMUS 的推断速度约为 SAM 的3倍。
